#!/usr/bin/env python3
"""
Test du pipeline complet : Extraction â†’ Chunking â†’ Embeddings â†’ Stockage PostgreSQL
Version corrigÃ©e pour pytest dans tests/integration/
"""

import sys
import os

# Fix du PYTHONPATH pour pytest depuis tests/integration/
current_dir = os.path.dirname(os.path.abspath(__file__))
root_dir = os.path.dirname(os.path.dirname(current_dir))
sys.path.insert(0, root_dir)

from src.data_extraction.extractors.service_public import ServicePublicExtractor
from src.data_processing.text_processor import TextProcessor
from src.embeddings.generator import EmbeddingsGenerator
from src.database.vector_storage import VectorStorage

def test_complete_rag_pipeline():
    """Test du pipeline RAG complet de bout en bout"""
    print("ğŸš€ TEST PIPELINE RAG COMPLET")
    print("=" * 70)
    
    # 1. EXTRACTION - RÃ©cupÃ©rer document rÃ©el
    print("ğŸ“„ 1. EXTRACTION - Service-Public.fr")
    print("-" * 40)
    
    extractor = ServicePublicExtractor()
    doc = extractor.extract_single_test_fiche()
    
    if not doc:
        print("âŒ Impossible de rÃ©cupÃ©rer un document")
        return False
    
    print(f"âœ… Document extrait: {doc.title[:60]}...")
    print(f"ğŸ“Š MÃ©tadonnÃ©es: {doc.domain}/{doc.metadata.get('subcategory', 'N/A')}")
    print(f"ğŸ“ Taille: {len(doc.content)} caractÃ¨res")
    print(f"ğŸ”— Source: {doc.source_url}")
    
    # 2. CHUNKING - DÃ©coupage intelligent
    print(f"\nâœ‚ï¸ 2. CHUNKING - DÃ©coupage intelligent")
    print("-" * 40)
    
    processor = TextProcessor(chunk_size=250, overlap=40)
    chunks = processor.process_document(
        title=doc.title,
        content=doc.content,
        metadata={
            'source_url': doc.source_url,
            'domain': doc.domain,
            'fiche_number': doc.metadata.get('fiche_number'),
            'subcategory': doc.metadata.get('subcategory')
        }
    )
    
    if not chunks:
        print("âŒ Aucun chunk crÃ©Ã©")
        return False
    
    print(f"âœ… {len(chunks)} chunks crÃ©Ã©s")
    content_chunks = [c for c in chunks if c.chunk_type == 'content']
    title_chunks = [c for c in chunks if c.chunk_type == 'title']
    print(f"ğŸ“‹ RÃ©partition: {len(title_chunks)} titre(s), {len(content_chunks)} contenu(s)")
    
    # 3. EMBEDDINGS - GÃ©nÃ©ration vecteurs
    print(f"\nğŸ§  3. EMBEDDINGS - GÃ©nÃ©ration vecteurs")
    print("-" * 40)
    
    generator = EmbeddingsGenerator()
    if not generator.load_model():
        print("âŒ Impossible de charger le modÃ¨le")
        return False
    
    chunk_embeddings = generator.process_text_chunks(chunks)
    
    successful_embeddings = sum(1 for _, emb in chunk_embeddings if emb is not None)
    print(f"âœ… Embeddings gÃ©nÃ©rÃ©s: {successful_embeddings}/{len(chunks)}")
    
    if successful_embeddings == 0:
        print("âŒ Aucun embedding gÃ©nÃ©rÃ©")
        return False
    
    # 4. STOCKAGE - PostgreSQL + pgvector
    print(f"\nğŸ—„ï¸ 4. STOCKAGE - PostgreSQL + pgvector")
    print("-" * 40)
    
    storage = VectorStorage()
    if not storage.connect():
        print("âŒ Impossible de se connecter Ã  PostgreSQL")
        print("ğŸ’¡ Assurez-vous que Docker est lancÃ© : docker-compose up -d")
        return False
    
    # Stocker le document complet avec ses chunks
    document_id = storage.store_document_with_chunks(doc, chunk_embeddings)
    
    if not document_id:
        print("âŒ Ã‰chec stockage document")
        storage.disconnect()
        return False
    
    print(f"âœ… Document stockÃ© avec ID: {document_id}")
    
    # 5. VALIDATION - Test recherche vectorielle
    print(f"\nğŸ” 5. VALIDATION - Test recherche vectorielle")
    print("-" * 40)
    
    # Test de recherche simple
    test_results = storage.test_vector_search("formation professionnelle")
    
    if 'error' in test_results:
        print(f"âš ï¸ Erreur test recherche: {test_results['error']}")
    else:
        print(f"âœ… Test recherche: {test_results['sample_chunks_found']} chunks trouvÃ©s")
        
        if test_results['sample_data']:
            print("\nğŸ“‹ Ã‰chantillon de donnÃ©es stockÃ©es:")
            for i, chunk_data in enumerate(test_results['sample_data'], 1):
                print(f"   {i}. {chunk_data['chunk_text']}")
                print(f"      Document: {chunk_data['document_title']} ({chunk_data['domain']})")
    
    # 6. STATISTIQUES - Performance globale
    print(f"\nğŸ“Š 6. STATISTIQUES - Performance globale")
    print("-" * 40)
    
    storage_stats = storage.get_storage_stats()
    embedding_stats = generator.get_embedding_stats()
    
    print(f"ğŸ—„ï¸ Base de donnÃ©es:")
    print(f"   - Documents totaux: {storage_stats.get('total_documents', 0)}")
    print(f"   - Chunks totaux: {storage_stats.get('total_chunks', 0)}")
    print(f"   - Taille moyenne chunk: {storage_stats.get('average_chunk_length', 0):.0f} chars")
    
    if 'documents_by_domain' in storage_stats:
        print(f"   - RÃ©partition domaines: {storage_stats['documents_by_domain']}")
    
    print(f"\nğŸ§  Embeddings:")
    print(f"   - ModÃ¨le: {embedding_stats['model_name']}")
    print(f"   - Dimension: {embedding_stats['embedding_dimension']}D")
    print(f"   - Performance: {embedding_stats['average_time_per_embedding']:.3f}s/embedding")
    print(f"   - Total gÃ©nÃ©rÃ©: {embedding_stats['total_embeddings_generated']}")
    
    print(f"\nğŸ’¾ Stockage:")
    print(f"   - Documents stockÃ©s: {storage_stats['documents_stored']}")
    print(f"   - Chunks stockÃ©s: {storage_stats['chunks_stored']}")
    print(f"   - Temps total: {storage_stats['total_storage_time']:.2f}s")
    
    # Fermer connexion
    storage.disconnect()
    
    # 7. RÃ‰SULTAT FINAL
    print(f"\nğŸ‰ 7. RÃ‰SULTAT FINAL")
    print("-" * 25)
    
    print("âœ… PIPELINE RAG COMPLET FONCTIONNEL !")
    print("âœ… Extraction automatisÃ©e")
    print("âœ… Chunking intelligent") 
    print("âœ… Embeddings 384D gÃ©nÃ©rÃ©s")
    print("âœ… Stockage vectoriel opÃ©rationnel")
    print("âœ… Recherche sÃ©mantique prÃªte")
    
    print(f"\nğŸ¯ PROCHAINES Ã‰TAPES:")
    print("ğŸ“‹ 5. Orchestration Airflow")
    print("âš¡ 6. API FastAPI")
    print("ğŸ’¬ 7. Interface Streamlit")
    
    return True

# Pour exÃ©cution directe (python test_complete_pipeline.py)
def main():
    success = test_complete_rag_pipeline()
    sys.exit(0 if success else 1)

# Pour pytest (pytest tests/integration/test_complete_pipeline.py)
def test_integration_complete_pipeline():
    """Test d'intÃ©gration complet pour pytest"""
    assert test_complete_rag_pipeline() == True

if __name__ == "__main__":
    main()