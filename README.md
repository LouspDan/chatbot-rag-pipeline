# ğŸ¤– Chatbot RAG Pipeline - DonnÃ©es Juridiques/RH

> **Pipeline automatisÃ© d'extraction et d'ingestion de donnÃ©es dans une base vectorielle pour chatbot conversationnel**

## ğŸ“‹ Description

SystÃ¨me automatisÃ© qui extrait des donnÃ©es juridiques et RH depuis des sources officielles franÃ§aises, les transforme en embeddings vectoriels, et les stocke dans une base de donnÃ©es optimisÃ©e pour la recherche sÃ©mantique.

**Cas d'usage :** Assistant intelligent pour prÃ©-qualification des demandes clients d'un cabinet de conseil.

## ğŸ—‚ï¸ Architecture

![Architecture RAG Pipeline](docs/architecture_pipeline.png)

Pour une vue interactive complÃ¨te : [Ouvrir le diagramme](docs/architecture_diagram.html)

## ğŸ› ï¸ Stack Technique

- **Langage :** Python 3.9+
- **Orchestration :** Apache Airflow
- **Base de donnÃ©es :** PostgreSQL + pgvector
- **Embeddings :** HuggingFace Sentence Transformers
- **API :** FastAPI
- **Interface :** Streamlit
- **Cloud :** Google Cloud Platform
- **Containerisation :** Docker

## ğŸ“ Structure du Projet

```
chatbot-rag-pipeline/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data_extraction/          # Extracteurs spÃ©cialisÃ©s
â”‚   â”œâ”€â”€ data_processing/          # Chunking et transformation
â”‚   â”œâ”€â”€ embeddings/              # GÃ©nÃ©ration embeddings
â”‚   â””â”€â”€ database/               # Gestion base vectorielle
â”œâ”€â”€ airflow/
â”‚   â”œâ”€â”€ dags/                   # Workflows automatisÃ©s
â”‚   â””â”€â”€ plugins/               # Extensions custom
â”œâ”€â”€ api/                       # API REST FastAPI
â”œâ”€â”€ streamlit/                # Interface dÃ©monstration
â”œâ”€â”€ tests/                    # Tests unitaires/intÃ©gration
â””â”€â”€ docs/                    # Documentation technique
```

## ğŸš€ Installation & DÃ©marrage

### PrÃ©requis
- Python 3.9+
- Docker & Docker Compose
- Git

### Setup
```bash
# Cloner le repository
git clone https://github.com/LouspDan/chatbot-rag-pipeline.git
cd chatbot-rag-pipeline

# Installer les dÃ©pendances
pip install -r requirements.txt

# DÃ©marrer l'environnement
docker-compose up -d

# Tests de validation
python test_pgvector.py
python test_service_public.py
```

## ğŸ“Š FonctionnalitÃ©s ImplÃ©mentÃ©es

### âœ… Phase 1 - Extraction & Stockage
- [x] Extracteur Service-Public.fr avec dÃ©couverte automatique
- [x] Classification hiÃ©rarchique (juridique/RH/Ã©conomique)
- [x] Base PostgreSQL + pgvector opÃ©rationnelle
- [x] Tests de recherche vectorielle

### ğŸ”„ Phase 2 - Processing (En cours)
- [x] Chunking intelligent avec overlap
- [x] GÃ©nÃ©ration embeddings automatisÃ©e
- [x] Pipeline complet extraction â†’ vectorisation

### ğŸ“… Phase 3 - Orchestration (PlanifiÃ©)
- [ ] DAGs Airflow pour automation
- [ ] Monitoring et alerting
- [ ] Gestion des erreurs et retry

### ğŸ“… Phase 4 - Interface (PlanifiÃ©)
- [ ] API REST pour recherche sÃ©mantique
- [ ] Interface Streamlit de dÃ©monstration
- [ ] DÃ©ploiement GCP

## ğŸ§ª Tests Disponibles

```bash
# Test base vectorielle
python test_pgvector.py

# Test extracteur spÃ©cialisÃ©
python test_service_public.py

# Test processeur de texte
python test_text_processor.py
```

## ğŸ“ˆ Performances Actuelles

- **Extraction :** ~21 fiches/minute (respectueux des serveurs)
- **Classification :** 95% de prÃ©cision sur domaines principaux
- **Chunking :** Segments de 150-300 caractÃ¨res avec overlap intelligent
- **Recherche :** <3 secondes pour 1000+ documents

## ğŸ” Limites & Perspectives

### Limites Techniques Actuelles
- Classification par mots-clÃ©s (vs LLM)
- Chunking fixe (vs sÃ©mantique adaptatif)
- Sources limitÃ©es au web scraping

### Ã‰volutions PrÃ©vues (2025)
- Migration vers chunking sÃ©mantique (LangChain)
- Classification LLM (GPT-4o-mini)
- Hybrid Search (Vector + BM25)
- IntÃ©gration APIs officielles

### Alternatives No-Code
- FaisabilitÃ© analysÃ©e : 80% des fonctionnalitÃ©s
- CoÃ»t : 150â‚¬/mois vs 20â‚¬/mois (solution actuelle)
- Recommandation : MVP no-code â†’ Migration code si succÃ¨s

## ğŸ‘¨â€ğŸ’» DÃ©veloppement

**Auteur :** Ã‰saÃ¯e LupepÃ©lÃ©  
**Objectif :** Portfolio technique - DÃ©monstration compÃ©tences Data Engineering  
**Context :** PrÃ©paration mission freelance automatisation RAG  

## ğŸ“œ Licence

MIT License 

---

**Status :** ğŸ”„ En dÃ©veloppement actif  
**DerniÃ¨re mise Ã  jour :** AoÃ»t 2025

---

## ğŸ§  CompÃ©tences mobilisÃ©es

### ğŸ”§ Data Engineering
- Pipelines ETL orchestrÃ©s avec Airflow
- Stockage vectoriel optimisÃ© pour la recherche sÃ©mantique
- API REST avec FastAPI

### ğŸ“Š Data Analytics
- Visualisation interactive avec Streamlit
- Structuration des donnÃ©es pour exploration intelligente

### ğŸ¤– Automatisation & IA
- Embeddings pour NLP et recherche sÃ©mantique
- Orchestration des tÃ¢ches et monitoring

---

## ğŸ’¼ Applications concrÃ¨tes
- Moteur de recherche intelligent sur des contenus juridiques
- Automatisation de la veille rÃ©glementaire
- Interface de consultation pour juristes, citoyens ou analystes
- Base pour assistants IA ou chatbots spÃ©cialisÃ©s en droit franÃ§ais

---

### ğŸš€ Disponible pour des missions similaires
**data engineering**, **automatisation**, **analyse de donnÃ©es** ou **intÃ©gration de solutions IA**.  

ğŸ‘‰ **Contactez-moi pour discuter de vos besoins ou de vos idÃ©es de projet.**

- **ğŸ’¼ Portfolio Complet :** [LinkedIn - Ã‰saÃ¯e  LUPEPÃ‰LÃ‰](https://www.linkedin.com/in/esaie-lupepele)
- **ğŸ”§ Autres Projets :** [Mapping Infor M3](https://github.com/LouspDan/Mapping-Infor-M3)
- **ğŸ“§ Profil Freelence  :** [Malt - Ã‰saÃ¯e LUPEPÃ‰LÃ‰]( https://www.malt.fr/profile/esaielupepele)
- **ğŸ“§ Contact Projet :** esaie.lupepele@gmail.com

